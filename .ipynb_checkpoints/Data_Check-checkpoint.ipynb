{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1> <font color=\"#2d97c4\"> Check that Data is Packed correctly, all sessions are accounted for, and no data is currapted or missed aligned </font> </h1> </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#since noteboke doesn't work in jupiterlabs    %matplotlib notebook \n",
    "%matplotlib inline \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/dana_z/ssd_2TB/6OHDA')\n",
    "#import mpld3\n",
    "#mpld3.enable_notebook()\n",
    "import numpy as np\n",
    "import scipy as sci\n",
    "from scipy import signal\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.colors as Mcolors\n",
    "import matplotlib.cm as cmx\n",
    "import sys\n",
    "import h5py\n",
    "from IO import *\n",
    "from utils import *\n",
    "from plotUtils import *\n",
    "from ColorSchems import colorPallet as CP\n",
    "import pptx\n",
    "from pptx import Presentation \n",
    "from pptx.util import Inches\n",
    "from io import BytesIO\n",
    "import re\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import sqlalchemy as db\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Files = ['FinalData_6OHDA.h5','FinalData_6OHDA_H.h5','FinalData_6OHDA_H_skip.h5','FinalData_6OHDA_skip.h5']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Make sure all sessions are in the struct </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FinalData_6OHDA.h5 : 214\n",
      "FinalData_6OHDA_H.h5 : 214\n",
      "FinalData_6OHDA_H_skip.h5 : 214\n",
      "FinalData_6OHDA_skip.h5 : 214\n"
     ]
    }
   ],
   "source": [
    "Sess = {}\n",
    "for dataFile in Files:\n",
    "    Sess[dataFile] = getSessionList(dataFile)\n",
    "    print(dataFile,':',len(Sess[dataFile]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> <span style=\"color:red;\"> Missing sessions:</span> </b> <br />\n",
    " <strike>1 -unknown<br />\n",
    " 1253_baselineS <br />\n",
    "1793_day34L <br />\n",
    "4539_BaselineA <br />\n",
    "7909_BaselineA2 <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> check which session miss partial data, how many TD tomato cells are in each session, and how many skipped cell in each session </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['File','Session','missing_traces',\n",
    "                             'missing_mvmt','missing_lfp','numRed','num_skip','creType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning up lfp data\n",
      "I deleted session: 1208_day12\n",
      "I deleted session: 2976_day4\n",
      "cleaning up mvmt data\n",
      "cleaning up trace data\n",
      "cleaning up lfp data\n",
      "I deleted session: 1208_day12\n",
      "I deleted session: 2976_day4\n",
      "cleaning up mvmt data\n",
      "cleaning up trace data\n",
      "cleaning up lfp data\n",
      "I deleted session: 1208_day12\n",
      "I deleted session: 2976_day4\n",
      "cleaning up mvmt data\n",
      "cleaning up trace data\n",
      "cleaning up lfp data\n",
      "I deleted session: 1208_day12\n",
      "I deleted session: 2976_day4\n",
      "cleaning up mvmt data\n",
      "cleaning up trace data\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for dataFile in Files:\n",
    "    sessions = Sess[dataFile]\n",
    "    skiped = dataFile.find('skip')!= -1\n",
    "    lfps = getData(dataFile,['lfp'])\n",
    "    lfps = list(lfps.keys())\n",
    "    mvmt = getData(dataFile,['mvmt'])\n",
    "    mvmt = list(mvmt.keys())\n",
    "    dff = getData(dataFile,['trace'])\n",
    "    dff = list(dff.keys())\n",
    "    for s in sessions:\n",
    "        d ={'File':dataFile,'Session':s}\n",
    "        m = s[0:4]\n",
    "        d['numRed'] = getNumRed(dataFile,m,s[5:])\n",
    "        d['missing_traces'] = s not in dff\n",
    "        if skiped and not  d['missing_traces']:\n",
    "            d['numSkip'] = np.sum(getSkipList(dataFile,m,s[5:]))\n",
    "        d['creType'] = getCreType(dataFile,m)\n",
    "        d['missing_lfp'] = not s in lfps\n",
    "        d['missing_mvmt'] = not s in mvmt\n",
    "        data.append(d)\n",
    "    \n",
    "df = pd.DataFrame(data)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'auto_processing'\n",
    "password = 'dz_preProcess'\n",
    "\n",
    "engine = db.create_engine('mysql+pymysql://'+user+':'+password+'@localhost/preProcess')\n",
    "df.to_sql('PackedData',engine,index =False,if_exists= 'replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_lfp</th>\n",
       "      <th>missing_mvmt</th>\n",
       "      <th>missing_traces</th>\n",
       "      <th>numRed</th>\n",
       "      <th>numSkip</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>File</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FinalData_6OHDA.h5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>302</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FinalData_6OHDA_H.h5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>302</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FinalData_6OHDA_H_skip.h5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>396</td>\n",
       "      <td>5544.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FinalData_6OHDA_skip.h5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>396</td>\n",
       "      <td>5544.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           missing_lfp  missing_mvmt  missing_traces  numRed  \\\n",
       "File                                                                           \n",
       "FinalData_6OHDA.h5                 2.0           0.0             0.0     302   \n",
       "FinalData_6OHDA_H.h5               2.0           0.0             0.0     302   \n",
       "FinalData_6OHDA_H_skip.h5          2.0           0.0             0.0     396   \n",
       "FinalData_6OHDA_skip.h5            2.0           0.0             0.0     396   \n",
       "\n",
       "                           numSkip  \n",
       "File                                \n",
       "FinalData_6OHDA.h5             0.0  \n",
       "FinalData_6OHDA_H.h5           0.0  \n",
       "FinalData_6OHDA_H_skip.h5   5544.0  \n",
       "FinalData_6OHDA_skip.h5     5544.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('File').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mouse'] = df.apply(lambda row: row.Session[0:4],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>numSkip</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>File</th>\n",
       "      <th>Session</th>\n",
       "      <th>missing_lfp</th>\n",
       "      <th>missing_mvmt</th>\n",
       "      <th>missing_traces</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">FinalData_6OHDA.h5</th>\n",
       "      <th>1208_day12</th>\n",
       "      <th>True</th>\n",
       "      <th>False</th>\n",
       "      <th>False</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2976_day4</th>\n",
       "      <th>True</th>\n",
       "      <th>False</th>\n",
       "      <th>False</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">FinalData_6OHDA_H.h5</th>\n",
       "      <th>1208_day12</th>\n",
       "      <th>True</th>\n",
       "      <th>False</th>\n",
       "      <th>False</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2976_day4</th>\n",
       "      <th>True</th>\n",
       "      <th>False</th>\n",
       "      <th>False</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">FinalData_6OHDA_H_skip.h5</th>\n",
       "      <th>1208_day12</th>\n",
       "      <th>True</th>\n",
       "      <th>False</th>\n",
       "      <th>False</th>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2976_day4</th>\n",
       "      <th>True</th>\n",
       "      <th>False</th>\n",
       "      <th>False</th>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">FinalData_6OHDA_skip.h5</th>\n",
       "      <th>1208_day12</th>\n",
       "      <th>True</th>\n",
       "      <th>False</th>\n",
       "      <th>False</th>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2976_day4</th>\n",
       "      <th>True</th>\n",
       "      <th>False</th>\n",
       "      <th>False</th>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                              numSkip\n",
       "File                      Session    missing_lfp missing_mvmt missing_traces         \n",
       "FinalData_6OHDA.h5        1208_day12 True        False        False               0.0\n",
       "                          2976_day4  True        False        False               0.0\n",
       "FinalData_6OHDA_H.h5      1208_day12 True        False        False               0.0\n",
       "                          2976_day4  True        False        False               0.0\n",
       "FinalData_6OHDA_H_skip.h5 1208_day12 True        False        False               9.0\n",
       "                          2976_day4  True        False        False              42.0\n",
       "FinalData_6OHDA_skip.h5   1208_day12 True        False        False               9.0\n",
       "                          2976_day4  True        False        False              42.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(df[(df.missing_lfp>0) | (df.missing_mvmt>0) | (df.missing_traces>0)] ,\n",
    "               values='numSkip', index=['File','Session','missing_lfp','missing_mvmt','missing_traces'],  aggfunc=np.sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 1208_day12 currupted LFP session, <br>\n",
    "    2976_day4 only 30s of LFP recorded </b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creType</th>\n",
       "      <th>CHI</th>\n",
       "      <th>NA</th>\n",
       "      <th>PV</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>File</th>\n",
       "      <th>mouse</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"16\" valign=\"top\">FinalData_6OHDA_H_skip.h5</th>\n",
       "      <th>0761</th>\n",
       "      <td>48.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>71.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>281.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>117.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2976</th>\n",
       "      <td>NaN</td>\n",
       "      <td>707.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2980</th>\n",
       "      <td>NaN</td>\n",
       "      <td>250.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2981</th>\n",
       "      <td>NaN</td>\n",
       "      <td>668.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4539</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>594.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7584</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7909</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2508.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8430</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8803</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8815</th>\n",
       "      <td>109.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "creType                            CHI     NA      PV\n",
       "File                      mouse                      \n",
       "FinalData_6OHDA_H_skip.h5 0761    48.0    NaN     NaN\n",
       "                          1208    71.0    NaN     NaN\n",
       "                          1222    36.0    NaN     NaN\n",
       "                          1231     4.0    NaN     NaN\n",
       "                          1236     NaN    NaN   281.0\n",
       "                          1253     9.0    NaN     NaN\n",
       "                          1793   117.0    NaN     NaN\n",
       "                          2976     NaN  707.0     NaN\n",
       "                          2980     NaN  250.0     NaN\n",
       "                          2981     NaN  668.0     NaN\n",
       "                          4539     NaN    NaN   594.0\n",
       "                          7584     NaN    NaN    98.0\n",
       "                          7909     NaN    NaN  2508.0\n",
       "                          8430     NaN    NaN    30.0\n",
       "                          8803     NaN    NaN    14.0\n",
       "                          8815   109.0    NaN     NaN"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(df[(df.File =='FinalData_6OHDA_H_skip.h5') & (df.numSkip>0)] ,\n",
    "               values='numSkip', index=['File', 'mouse'], columns=['creType'], aggfunc=np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creType</th>\n",
       "      <th>PV</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>File</th>\n",
       "      <th>Session</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"18\" valign=\"top\">FinalData_6OHDA_H_skip.h5</th>\n",
       "      <th>7909_BaselineA</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7909_day0</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7909_day1</th>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7909_day10</th>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7909_day11</th>\n",
       "      <td>340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7909_day12</th>\n",
       "      <td>285.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7909_day13</th>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7909_day14</th>\n",
       "      <td>280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7909_day15A</th>\n",
       "      <td>244.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7909_day2</th>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7909_day3</th>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7909_day30A</th>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7909_day4</th>\n",
       "      <td>121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7909_day5</th>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7909_day6</th>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7909_day7</th>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7909_day8</th>\n",
       "      <td>196.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7909_day9</th>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "creType                                      PV\n",
       "File                      Session              \n",
       "FinalData_6OHDA_H_skip.h5 7909_BaselineA    1.0\n",
       "                          7909_day0         4.0\n",
       "                          7909_day1        72.0\n",
       "                          7909_day10      300.0\n",
       "                          7909_day11      340.0\n",
       "                          7909_day12      285.0\n",
       "                          7909_day13       83.0\n",
       "                          7909_day14      280.0\n",
       "                          7909_day15A     244.0\n",
       "                          7909_day2        63.0\n",
       "                          7909_day3       107.0\n",
       "                          7909_day30A      14.0\n",
       "                          7909_day4       121.0\n",
       "                          7909_day5       135.0\n",
       "                          7909_day6       111.0\n",
       "                          7909_day7       107.0\n",
       "                          7909_day8       196.0\n",
       "                          7909_day9        45.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(df[(df.File =='FinalData_6OHDA_H_skip.h5') & (df.numSkip>0) & (df.mouse == '7909')] ,\n",
    "               values='numSkip', index=['File', 'Session'], columns=['creType'], aggfunc=np.sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> look at all traces that are marked as TD-tomato + skip </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning up trace data\n",
      "I deleted session: 0761_day1\n",
      "I deleted session: 0761_day12\n",
      "I deleted session: 0761_day14A\n",
      "I deleted session: 0761_day2\n",
      "I deleted session: 0761_day31A\n",
      "cleaning up trace data\n",
      "cleaning up trace data\n",
      "I deleted session: 1208_BaselineA\n",
      "cleaning up trace data\n",
      "cleaning up trace data\n",
      "I deleted session: 1222_BaselineA\n",
      "I deleted session: 1222_day11\n",
      "I deleted session: 1222_day13\n",
      "I deleted session: 1222_day2\n",
      "I deleted session: 1222_day20L\n",
      "I deleted session: 1222_day3\n",
      "I deleted session: 1222_day36L\n",
      "I deleted session: 1222_day5\n",
      "I deleted session: 1222_day7\n",
      "I deleted session: 1222_day9\n",
      "cleaning up trace data\n",
      "cleaning up trace data\n",
      "cleaning up trace data\n",
      "cleaning up trace data\n",
      "I deleted session: 1236_day19L\n",
      "cleaning up trace data\n",
      "cleaning up trace data\n",
      "I deleted session: 1253_BaselineA\n",
      "I deleted session: 1253_BaselineS\n",
      "cleaning up trace data\n",
      "cleaning up trace data\n",
      "I deleted session: 1793_BaselineA\n",
      "I deleted session: 1793_day19L\n",
      "I deleted session: 1793_day30A\n",
      "I deleted session: 1793_day34L\n",
      "cleaning up trace data\n",
      "cleaning up trace data\n",
      "I deleted session: 2976_BaselineA\n",
      "I deleted session: 2976_BaselineL\n",
      "I deleted session: 2976_BaselineS\n",
      "I deleted session: 2976_day10\n",
      "I deleted session: 2976_day12\n",
      "I deleted session: 2976_day14\n",
      "I deleted session: 2976_day15A\n",
      "I deleted session: 2976_day19L\n",
      "I deleted session: 2976_day2\n",
      "I deleted session: 2976_day30A\n",
      "I deleted session: 2976_day35L\n",
      "I deleted session: 2976_day4\n",
      "I deleted session: 2976_day6\n",
      "I deleted session: 2976_day8\n",
      "cleaning up trace data\n",
      "cleaning up trace data\n",
      "I deleted session: 2980_BaselineA\n",
      "I deleted session: 2980_BaselineL\n",
      "I deleted session: 2980_BaselineS\n",
      "I deleted session: 2980_day10\n",
      "I deleted session: 2980_day12\n",
      "I deleted session: 2980_day14\n",
      "I deleted session: 2980_day15A\n",
      "I deleted session: 2980_day19L\n",
      "I deleted session: 2980_day2\n",
      "I deleted session: 2980_day30A\n",
      "I deleted session: 2980_day35L\n",
      "I deleted session: 2980_day4\n",
      "I deleted session: 2980_day6\n",
      "I deleted session: 2980_day8\n",
      "cleaning up trace data\n",
      "cleaning up trace data\n",
      "I deleted session: 2981_BaselineA\n",
      "I deleted session: 2981_BaselineL\n",
      "I deleted session: 2981_BaselineS\n",
      "I deleted session: 2981_day10\n",
      "I deleted session: 2981_day12\n",
      "I deleted session: 2981_day14\n",
      "I deleted session: 2981_day15A\n",
      "I deleted session: 2981_day19L\n",
      "I deleted session: 2981_day2\n",
      "I deleted session: 2981_day30A\n",
      "I deleted session: 2981_day35L\n",
      "I deleted session: 2981_day4\n",
      "I deleted session: 2981_day6\n",
      "I deleted session: 2981_day8\n",
      "cleaning up trace data\n",
      "cleaning up trace data\n",
      "I deleted session: 4539_day5\n",
      "cleaning up trace data\n",
      "cleaning up trace data\n",
      "I deleted session: 7584_day0\n",
      "cleaning up trace data\n",
      "cleaning up trace data\n",
      "I deleted session: 7909_day30A\n",
      "cleaning up trace data\n",
      "cleaning up trace data\n",
      "I deleted session: 8430_BaselineA\n",
      "I deleted session: 8430_day1\n",
      "I deleted session: 8430_day15A\n",
      "I deleted session: 8430_day9\n",
      "cleaning up trace data\n",
      "cleaning up trace data\n",
      "I deleted session: 8803_day10\n",
      "I deleted session: 8803_day12\n",
      "I deleted session: 8803_day30A\n",
      "cleaning up trace data\n",
      "cleaning up trace data\n",
      "I deleted session: 8815_BaselineL\n",
      "I deleted session: 8815_day2\n",
      "cleaning up trace data\n"
     ]
    }
   ],
   "source": [
    "# global presentation\n",
    "Oprs = Presentation()    \n",
    "\n",
    "title_layout = Oprs.slide_layouts[5] \n",
    "title_slide_layout = Oprs.slide_layouts[0]\n",
    "\n",
    "slide = Oprs.slides.add_slide(title_slide_layout)\n",
    "slide.shapes.title.text = 'Skipped TD-tomato cells - per mouse'\n",
    "\n",
    "# position, size, and colors:\n",
    "lf= {'left':0.00, 'top':1.20, 'height':5.80, 'width':10.00}\n",
    "rawArgs = {'left':Inches(lf['left']),'top':Inches(lf['top']), 'height':Inches(lf['height']), 'width':Inches(lf['width'])}\n",
    "\n",
    "miceList = getMiceList(Files[2])\n",
    "for m in miceList:  \n",
    "    data = getData(Files[2],['trace'],period ='Pre', red=True, mice=m)\n",
    "    days = np.zeros(len(data))\n",
    "    ind = 0\n",
    "    for sess in data:\n",
    "        #store max min mean median \n",
    "        if sess[5] == 'B':\n",
    "            day = 0\n",
    "        else:\n",
    "            day = int(re.findall(r'\\d+',sess[5:])[0])\n",
    "        days[ind] = day\n",
    "        ind= ind+1\n",
    "    a = np.argsort(days)\n",
    "    dKeys = list(data.keys())\n",
    "    \n",
    "    for aa in range(0,len(data)):\n",
    "        sess = dKeys[a[aa]]\n",
    "        dff = data[sess]['trace']['dff']\n",
    "        numred = data[sess]['trace']['numred']\n",
    "        skiped = getSkipList(Files[2],m,sess[5:])\n",
    "        skiped = skiped[:numred]\n",
    "        if np.sum(skiped) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            slide = Oprs.slides.add_slide(title_layout)\n",
    "            slide.shapes.title.text = sess\n",
    "            dff = dff[skiped.astype('bool'),:]\n",
    "            dt = 1/data[sess]['trace']['FS']\n",
    "            fig, ax = plt.subplots(1,1,figsize=(lf['width'],lf['height']))\n",
    "            rosterPlot(ax, dff,dt,specing = np.max(dff), Color = None)\n",
    "            pic = plt2pptx(slide, fig, **rawArgs)\n",
    "            fig.clf()\n",
    "            plt.close(fig)\n",
    "        \n",
    "Oprs.save('ppts/skiiped_TDtomato.pptx')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Make sure lfp is not currupted (spectron looks reasonable) </b> <br />\n",
    "Store all sessions in ppt - so can look at each session individually later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global presentation handling:\n",
    "Oprs = Presentation() # store overall (1 slide/mouse)\n",
    "Iprs = Presentation() # store individual sessions\n",
    "\n",
    "title_layout = Oprs.slide_layouts[5] \n",
    "title_slide_layout = Oprs.slide_layouts[0]\n",
    "\n",
    "slide = Oprs.slides.add_slide(title_slide_layout)\n",
    "slide.shapes.title.text = 'lfp summary - per mouse'\n",
    "slide = Iprs.slides.add_slide(title_slide_layout)\n",
    "slide.shapes.title.text = 'lfp summary - per session'\n",
    "\n",
    "# global color scheme and positions:\n",
    "lf= {'left':0.64, 'top':1.85, 'height':2.07, 'width':8.25}\n",
    "sf= {'left':0.64, 'top':4.4, 'height':2.07, 'width':8.25}\n",
    "cf = {'left':1.35, 'top':1.46, 'height':5.58, 'width':7.14}\n",
    "rawArgs = {'left':Inches(lf['left']),'top':Inches(lf['top']), 'height':Inches(lf['height']), 'width':Inches(lf['width'])}\n",
    "specArgs = {'left':Inches(lf['left']),'top':Inches(sf['top']), 'height':Inches(lf['height']), 'width':Inches(lf['width'])}\n",
    "sumArgs = {'left':Inches(cf['left']),'top':Inches(cf['top']), 'height':Inches(cf['height']), 'width':Inches(cf['width'])}\n",
    "    # create the color maps\n",
    "\n",
    "cNorm = Mcolors.Normalize(vmin=1, vmax=35)\n",
    "cm = plt.get_cmap('YlOrRd')\n",
    "cMap = cmx.ScalarMappable(norm=cNorm, cmap = cm)\n",
    "\n",
    "miceList = getMiceList(Files[0])\n",
    "for m in miceList:  \n",
    "    data = getData(Files[0],['lfp'],period ='Pre', mice=m)\n",
    "    figt, axt = plt.subplots(1,1,figsize=(cf['width'],cf['height']))\n",
    "    figt.set_size_inches(cf['width'],cf['height'],forward=True)\n",
    "    days = np.zeros(len(data))\n",
    "    ind = 0\n",
    "    for sess in data:\n",
    "        #store max min mean median \n",
    "        if sess[5] == 'B':\n",
    "            day = 0\n",
    "        else:\n",
    "            day = int(re.findall(r'\\d+',sess[5:])[0])\n",
    "        days[ind] = day\n",
    "        ind= ind+1\n",
    "    a = np.argsort(days)\n",
    "    dKeys = list(data.keys())\n",
    "    for aa in range(0,len(data)):\n",
    "#        try:\n",
    "        sess = dKeys[a[aa]]\n",
    "        slide = Iprs.slides.add_slide(title_layout)\n",
    "        slide.shapes.title.text = sess\n",
    "        lfp = data[sess]['lfp']['lfp']\n",
    "        Fs = data[sess]['lfp']['FS']\n",
    "        # plot raw lfp:\n",
    "        fig, ax = plt.subplots(1,1,figsize=(lf['width'],lf['height']))\n",
    "        ax.plot(lfp)\n",
    "        fig.set_size_inches(lf['width'],lf['height'], forward=True)\n",
    "        pic = plt2pptx(slide, fig, **rawArgs)\n",
    "        fig.clf()\n",
    "        plt.close(fig)\n",
    "        # plot spectogram:\n",
    "        f, t, Sxx = signal.spectrogram(lfp[:,0],Fs,window=('hamming'),nperseg=140*8,noverlap =120*8,nfft=1200*8)\n",
    "        Pxx = 10*np.log10(np.abs(Sxx))\n",
    "        Pxx[np.isinf(Pxx)] = 0\n",
    "        tlfp = np.linspace(0,lfp.size*(1/Fs),lfp.size)\n",
    "        fig, ax = plt.subplots(1,1,figsize=(lf['width'],lf['height']))\n",
    "        fig.set_size_inches(lf['width'],lf['height'], forward=True)\n",
    "        ind = np.searchsorted(f,100)\n",
    "        ax.pcolormesh(t,f[:ind],Pxx[:ind,:],vmin=-170,vmax=-70, cmap='jet')\n",
    "        ax.set_ylim((5,100))\n",
    "        pic = plt2pptx(slide, fig, **specArgs)\n",
    "        fig.clf()\n",
    "        plt.close(fig)\n",
    "        # plot spectrom in the right color on fig_t\n",
    "        if sess[5] == 'B':\n",
    "            day = 0\n",
    "            colorVal  = 'green'\n",
    "        else:\n",
    "            day = int(re.findall(r'\\d+',sess[5:])[0])\n",
    "            colorVal = cMap.to_rgba(day)\n",
    "\n",
    "        Power = np.sum(Sxx[:ind,:],1)\n",
    "        totPower = np.sum(Power)\n",
    "        if totPower == 0:\n",
    "            totPower = 1\n",
    "        M = Power/totPower    \n",
    "        axt.plot(f[:ind],M,color = colorVal, label = str(day))\n",
    "        axt.set_xlim((5,100))\n",
    "        del f\n",
    "        gc.collect()\n",
    "#        except:\n",
    "#            print(m,sess)\n",
    "#            continue\n",
    "    slide = Oprs.slides.add_slide(title_layout)\n",
    "    slide.shapes.title.text = m\n",
    "    handles,labels = axt.get_legend_handles_labels()\n",
    "    axt.legend(handles, labels, loc='upper right')\n",
    "    pic = plt2pptx(slide, figt, **sumArgs)\n",
    "    figt.clf()\n",
    "    plt.close(figt)\n",
    "Iprs.save('ppts/lfp_individual_'+m+'.pptx')\n",
    "Oprs.save('ppts/lfp_Overall_Mice.pptx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> <span style=\"color:red;\">Currapted lfp sessions:</span> </b> <br />\n",
    "<strike> 1208_day12 --> all session </strike> session removed <br />\n",
    "1236_day30A --> ~30s-180s <br />\n",
    "1236_day35L --> ~30s-300s <br />\n",
    "\n",
    "<b> <span style=\"color:red;\">Short/missing lfp sessions:</span> </b> <br />\n",
    "2976_day4 <br />\n",
    "\n",
    "<b> <span style=\"color:red;\">Excessive outliers in lfp:</span> </b> <br />\n",
    "2981_day15A - many <br />\n",
    "8803_day10 - 1 outlier <br />\n",
    "8815_day19L - 1 outlier <br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n"
     ]
    }
   ],
   "source": [
    "# define presentation params:\n",
    "prs = Presentation()\n",
    "prs.slide_width = Inches(11)\n",
    "title_layout = prs.slide_layouts[5] \n",
    "title_slide_layout = prs.slide_layouts[0]\n",
    "\n",
    "slide = prs.slides.add_slide(title_slide_layout)\n",
    "slide.shapes.title.text = 'Mvmt onset'\n",
    "# define figure params:\n",
    "lf = {'left':0.30, 'top':1.30, 'height':5.80, 'width':10.10}\n",
    "fArgs = {'left':Inches(lf['left']),'top':Inches(lf['top']), 'height':Inches(lf['height']), 'width':Inches(lf['width'])}\n",
    "Colors = CP('mvmtType')\n",
    "th = 2\n",
    "hi = 9 \n",
    "hiWin=40 \n",
    "thWin=30\n",
    "shift=3\n",
    "\n",
    "# get mice list:\n",
    "miceList = getMiceList(Files[0])\n",
    "# prepare data storage for segments:\n",
    "# make plot and save as ppt\n",
    "for m in miceList:\n",
    "    data = getData(Files[0],['speed'],period ='Pre', mice=m)\n",
    "    days = np.zeros(len(data))\n",
    "    ind = 0\n",
    "    # sort by session for my own OCD\n",
    "    for sess in data:\n",
    "        if sess[5] == 'B':\n",
    "            day = 0\n",
    "        else:\n",
    "            day = int(re.findall(r'\\d+',sess[5:])[0])\n",
    "        days[ind] = day\n",
    "        ind= ind+1\n",
    "    a = np.argsort(days)\n",
    "    dKeys = list(data.keys())\n",
    "    # calculte high speed period, do 3 sessions per plot, and stor in ppt\n",
    "    ind = 0;\n",
    "    for aa in range(0,len(data)):\n",
    "        sess = dKeys[a[aa]]\n",
    "        speed = data[sess]['speed']['speed']\n",
    "        speed = speed.T\n",
    "        smoothSpeed = smooth(speed,20)\n",
    "        dt  = 1/data[sess]['speed']['Fs']\n",
    "        if ind%3==0:\n",
    "            fig, ax = plt.subplots(3,1,figsize=(lf['width'],lf['height']),\n",
    "                                   gridspec_kw = {'top':0.995,'bottom':0.008,'wspace':0.1})\n",
    "            fig.set_size_inches(lf['width'],lf['height'],forward=True)\n",
    "            fig.subplots_adjust(left=0.03, right=0.99)\n",
    "            slide = prs.slides.add_slide(title_layout)\n",
    "            slide.shapes.title.text = m + 'params: th='+ str(th) + ' hi='+ str(hi)\n",
    "        try:    \n",
    "            sOnset = FindMvmtOnset(speed,th,hi,hiWin,thWin, shift)\n",
    "            t = np.linspace(0,len(speed)*dt,len(speed))\n",
    "            ax[ind%3].plot(t,speed)\n",
    "            ax[ind%3].plot(t,smoothSpeed, color='black')\n",
    "            ax[ind%3].plot(t[sOnset],smoothSpeed[sOnset],'X',color='firebrick')\n",
    "            ax[ind%3].set_xlim(0,600)\n",
    "        except:\n",
    "            print('error')\n",
    "        ax[ind%3].set_title(sess)\n",
    "        if ind%3==2 or aa ==len(data)-1:\n",
    "            pic = plt2pptx(slide, fig, **fArgs)\n",
    "            plt.close(fig)\n",
    "        ind = ind+1\n",
    "prs.save('ppts/SpeedOnset_final.pptx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> <font color=\"#2d97c4\"> Check Movement onset and high/low speed  </font> </b> <br />\n",
    "since mvmt onset not ideal for all mice, change policty to reflect parameters based on mice baseline sessions<br />\n",
    "<br />\n",
    "\n",
    "Recipee: <br />\n",
    "<b> 1) </b> look at 3 baseline session for mouse and detrmine speed statistics <br />\n",
    "<b> 2) </b> from 1, automatically chooce params for speed onset <br />\n",
    "<b> 3) </b> use params from 2 to find mvmt onset for all session and store in hdf5 dataset <br />\n",
    "<b> 4) </b> implement an i/o function that load speed onset for session <br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n"
     ]
    }
   ],
   "source": [
    "# visualize Baseline speed range, quantiles, mean, median, std for all mice.\n",
    "miceList = getMiceList(Files[0])\n",
    "speedData = []\n",
    "for m in miceList:\n",
    "    data = getData(Files[0],['speed'],period ='Pre',mice=m, day = lambda x: x==0)\n",
    "    for sess in data:\n",
    "        speed = data[sess]['speed']['speed']\n",
    "        d ={'Session':sess[5:], 'Mouse':m,'min':np.min(speed),'max':np.max(speed),\n",
    "            'std':np.std(speed),'mean':np.mean(speed)}\n",
    "        Q = np.quantile(speed,[.25,.5,.75])\n",
    "        d['Q25'],d['Q50'],d['Q75'] =np.quantile(speed,[.25,.5,.75])\n",
    "        d['Q25_std'] = np.std(speed[np.where(speed<=d['Q25'])])\n",
    "    \n",
    "        \n",
    "        speedData.append(d)\n",
    "    \n",
    "df = pd.DataFrame(speedData)\n",
    "df.to_sql('SpeedData',engine,index =False,if_exists= 'replace')        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning up speed data\n",
      "0761  hi:  9.093602196045618\n",
      "cleaning up speed data\n",
      "1208  hi:  8.771471533672353\n",
      "cleaning up speed data\n",
      "1222  hi:  5.156689209415026\n",
      "cleaning up speed data\n",
      "1231  hi:  11.618820172401003\n",
      "cleaning up speed data\n",
      "1236  hi:  4.7582281732347065\n",
      "cleaning up speed data\n",
      "1253  hi:  6.589833466357713\n",
      "cleaning up speed data\n",
      "1793  hi:  6.682175945902453\n",
      "cleaning up speed data\n",
      "2976  hi:  3.31284333461864\n",
      "cleaning up speed data\n",
      "2980  hi:  2.454958217734436\n",
      "cleaning up speed data\n",
      "2981  hi:  6.1404716594406485\n",
      "cleaning up speed data\n",
      "4539  hi:  20.02124398644328\n",
      "cleaning up speed data\n",
      "7584  hi:  20.05099337143352\n",
      "cleaning up speed data\n",
      "7909  hi:  19.047091800698265\n",
      "cleaning up speed data\n",
      "8430  hi:  9.830010517302346\n",
      "cleaning up speed data\n",
      "8803  hi:  4.064502492829341\n",
      "cleaning up speed data\n",
      "8815  hi:  5.469190903653327\n"
     ]
    }
   ],
   "source": [
    "miceList = getMiceList(Files[0])\n",
    "speedOnsetPars = {}\n",
    "for m in miceList:\n",
    "    data = getData(Files[0],['speed'],period ='Pre',mice=m, day = lambda x: x==0)\n",
    "    maxSpeed = [];\n",
    "    for sess in data:\n",
    "        speed = smooth(data[sess]['speed']['speed'],20)\n",
    "        maxSpeed.append(np.max(speed))\n",
    "    hi = np.mean(maxSpeed)/4\n",
    "    print(m,' hi: ',hi)\n",
    "    speedOnsetPars[m] = hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n"
     ]
    }
   ],
   "source": [
    "# define presentation params:\n",
    "prs = Presentation()\n",
    "prs.slide_width = Inches(11)\n",
    "title_layout = prs.slide_layouts[5] \n",
    "title_slide_layout = prs.slide_layouts[0]\n",
    "\n",
    "slide = prs.slides.add_slide(title_slide_layout)\n",
    "slide.shapes.title.text = 'Mvmt onset'\n",
    "# define figure params:\n",
    "lf = {'left':0.30, 'top':1.30, 'height':5.80, 'width':20.10}\n",
    "fArgs = {'left':Inches(lf['left']),'top':Inches(lf['top']), 'height':Inches(lf['height']), 'width':Inches(lf['width'])}\n",
    "Colors = CP('mvmtType') \n",
    "\n",
    "hiWin=20 \n",
    "thWin=40\n",
    "th_strong = 1\n",
    "shift=2\n",
    "\n",
    "# get mice list:\n",
    "miceList = getMiceList(Files[0])\n",
    "# prepare data storage for segments:\n",
    "# make plot and save as ppt\n",
    "for m in miceList:\n",
    "    data = getData(Files[0],['speed'],period ='Pre', mice=m)\n",
    "    days = np.zeros(len(data))\n",
    "    ind = 0\n",
    "    # sort by session for my own OCD\n",
    "    for sess in data:\n",
    "        if sess[5] == 'B':\n",
    "            day = 0\n",
    "        else:\n",
    "            day = int(re.findall(r'\\d+',sess[5:])[0])\n",
    "        days[ind] = day\n",
    "        ind= ind+1\n",
    "    a = np.argsort(days)\n",
    "    dKeys = list(data.keys())\n",
    "    # calculte high speed period, do 3 sessions per plot, and stor in ppt\n",
    "    ind = 0;\n",
    "    hi =  speedOnsetPars[m] \n",
    "    th_weak = np.min([3.3, hi/2.5])\n",
    "    for aa in range(0,len(data)):\n",
    "        sess = dKeys[a[aa]]\n",
    "        speed = data[sess]['speed']['speed']\n",
    "        speed = speed.T\n",
    "        smoothSpeed = smooth(speed,20)\n",
    "        dt  = 1/data[sess]['speed']['Fs']\n",
    "        if ind%3==0:\n",
    "            fig, ax = plt.subplots(3,1,figsize=(lf['width'],lf['height']),\n",
    "                                   gridspec_kw = {'top':0.995,'bottom':0.008,'wspace':0.1})\n",
    "            fig.set_size_inches(lf['width'],lf['height'],forward=True)\n",
    "            fig.subplots_adjust(left=0.03, right=0.99)\n",
    "            slide = prs.slides.add_slide(title_layout)\n",
    "            slide.shapes.title.text = m + 'params: th_weak='+ str(round(th_weak,2)) + ' hi='+ str(round(hi,2))\n",
    "        try:    \n",
    "            sOnset = FindMvmtOnset2(speed, th_weak,th_strong ,hi,hiWin,thWin,shift)\n",
    "            t = np.linspace(0,len(speed)*dt,len(speed))\n",
    "            ax[ind%3].plot(t,speed)\n",
    "            ax[ind%3].plot(t,smoothSpeed, color='black')\n",
    "            ax[ind%3].plot(t[sOnset],smoothSpeed[sOnset],'X',color='firebrick')\n",
    "            ax[ind%3].set_xlim(0,600)\n",
    "        except:\n",
    "            print('error')\n",
    "        ax[ind%3].set_title(sess)\n",
    "        if ind%3==2 or aa ==len(data)-1:\n",
    "            pic = plt2pptx(slide, fig, **fArgs)\n",
    "            plt.close(fig)\n",
    "        ind = ind+1\n",
    "prs.save('ppts/SpeedOnset_Final3.pptx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Document final decision on mvmt onset algo, <br />\n",
    "    pack into an hdf5 file, <br />\n",
    "    and write an I/O function to load them. \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hiWin=20 <br />\n",
    "thWin=40 <br />\n",
    "th_strong = 1 <br />\n",
    "shift=2 <br />\n",
    "\n",
    "hi = np.mean(maxSpeed)/4 where max speed is smooth with 1s rolling window for all 3 baseline sessions <br />\n",
    "th_weak = np.min([3.3, hi/2.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "I deleted session: 0761_day1\n",
      "I deleted session: 0761_day10\n",
      "I deleted session: 0761_day12\n",
      "I deleted session: 0761_day2\n",
      "I deleted session: 0761_day4\n",
      "I deleted session: 0761_day6\n",
      "I deleted session: 0761_day8\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "I deleted session: 1208_day10\n",
      "I deleted session: 1208_day12\n",
      "I deleted session: 1208_day14\n",
      "I deleted session: 1208_day2\n",
      "I deleted session: 1208_day4\n",
      "I deleted session: 1208_day6\n",
      "I deleted session: 1208_day8\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "I deleted session: 1222_day11\n",
      "I deleted session: 1222_day13\n",
      "I deleted session: 1222_day2\n",
      "I deleted session: 1222_day3\n",
      "I deleted session: 1222_day5\n",
      "I deleted session: 1222_day7\n",
      "I deleted session: 1222_day9\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "I deleted session: 1236_day1\n",
      "I deleted session: 1236_day11\n",
      "I deleted session: 1236_day13\n",
      "I deleted session: 1236_day3\n",
      "I deleted session: 1236_day5\n",
      "I deleted session: 1236_day7\n",
      "I deleted session: 1236_day9\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "I deleted session: 1793_day10\n",
      "I deleted session: 1793_day12\n",
      "I deleted session: 1793_day14\n",
      "I deleted session: 1793_day2\n",
      "I deleted session: 1793_day4\n",
      "I deleted session: 1793_day6\n",
      "I deleted session: 1793_day8\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "I deleted session: 2976_day10\n",
      "I deleted session: 2976_day12\n",
      "I deleted session: 2976_day14\n",
      "I deleted session: 2976_day2\n",
      "I deleted session: 2976_day4\n",
      "I deleted session: 2976_day6\n",
      "I deleted session: 2976_day8\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "I deleted session: 2980_day10\n",
      "I deleted session: 2980_day12\n",
      "I deleted session: 2980_day14\n",
      "I deleted session: 2980_day2\n",
      "I deleted session: 2980_day4\n",
      "I deleted session: 2980_day6\n",
      "I deleted session: 2980_day8\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "I deleted session: 2981_day10\n",
      "I deleted session: 2981_day12\n",
      "I deleted session: 2981_day14\n",
      "I deleted session: 2981_day2\n",
      "I deleted session: 2981_day4\n",
      "I deleted session: 2981_day6\n",
      "I deleted session: 2981_day8\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "I deleted session: 4539_day0\n",
      "I deleted session: 4539_day1\n",
      "I deleted session: 4539_day10\n",
      "I deleted session: 4539_day11\n",
      "I deleted session: 4539_day12\n",
      "I deleted session: 4539_day13\n",
      "I deleted session: 4539_day14\n",
      "I deleted session: 4539_day2\n",
      "I deleted session: 4539_day3\n",
      "I deleted session: 4539_day4\n",
      "I deleted session: 4539_day5\n",
      "I deleted session: 4539_day6\n",
      "I deleted session: 4539_day7\n",
      "I deleted session: 4539_day8\n",
      "I deleted session: 4539_day9\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "I deleted session: 7584_Baseline0\n",
      "I deleted session: 7584_day0\n",
      "I deleted session: 7584_day1\n",
      "I deleted session: 7584_day10\n",
      "I deleted session: 7584_day11\n",
      "I deleted session: 7584_day12\n",
      "I deleted session: 7584_day15\n",
      "I deleted session: 7584_day2\n",
      "I deleted session: 7584_day3\n",
      "I deleted session: 7584_day4\n",
      "I deleted session: 7584_day5\n",
      "I deleted session: 7584_day6\n",
      "I deleted session: 7584_day7\n",
      "I deleted session: 7584_day8\n",
      "I deleted session: 7584_day9\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "I deleted session: 7909_day0\n",
      "I deleted session: 7909_day1\n",
      "I deleted session: 7909_day10\n",
      "I deleted session: 7909_day11\n",
      "I deleted session: 7909_day12\n",
      "I deleted session: 7909_day13\n",
      "I deleted session: 7909_day14\n",
      "I deleted session: 7909_day2\n",
      "I deleted session: 7909_day3\n",
      "I deleted session: 7909_day4\n",
      "I deleted session: 7909_day5\n",
      "I deleted session: 7909_day6\n",
      "I deleted session: 7909_day7\n",
      "I deleted session: 7909_day8\n",
      "I deleted session: 7909_day9\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "I deleted session: 8430_day1\n",
      "I deleted session: 8430_day11\n",
      "I deleted session: 8430_day3\n",
      "I deleted session: 8430_day5\n",
      "I deleted session: 8430_day7\n",
      "I deleted session: 8430_day9\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "I deleted session: 8803_day10\n",
      "I deleted session: 8803_day12\n",
      "I deleted session: 8803_day14\n",
      "I deleted session: 8803_day2\n",
      "I deleted session: 8803_day4\n",
      "I deleted session: 8803_day5\n",
      "I deleted session: 8803_day6\n",
      "I deleted session: 8803_day8\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "I deleted session: 8815_day10\n",
      "I deleted session: 8815_day12\n",
      "I deleted session: 8815_day14\n",
      "I deleted session: 8815_day2\n",
      "I deleted session: 8815_day4\n",
      "I deleted session: 8815_day6\n",
      "I deleted session: 8815_day8\n"
     ]
    }
   ],
   "source": [
    "# create hdf5 file with all the mice and mvmt Onset\n",
    "f = h5py.File('OnsetsAndPeriods.hdf5','a')\n",
    "\n",
    "hiWin=20 \n",
    "thWin=40\n",
    "th_strong = 1\n",
    "shift=2\n",
    "\n",
    "miceList = speedOnsetPars.keys()\n",
    "for m in miceList:\n",
    "    grp = f.create_group(m)\n",
    "    sgrp = grp.create_group('mvmtOnset_params')\n",
    "    sgrp.attrs['hi'] = speedOnsetPars[m]\n",
    "    sgrp.attrs['th_weak'] = np.min([3.3, speedOnsetPars[m]/2.5])\n",
    "    sgrp.attrs['hiWin'] = hiWin\n",
    "    sgrp.attrs['thWin'] = thWin\n",
    "    sgrp.attrs['th_strong'] = th_strong\n",
    "    sgrp.attrs['shift'] = shift\n",
    "    data_pre = getData(Files[0],['speed'],period ='Pre', mice=m)\n",
    "    data_post = getData(Files[0],['speed'],period ='Post', mice=m)\n",
    "    days = np.zeros(len(data_pre))\n",
    "    ind = 0\n",
    "    # sort by session for my own OCD\n",
    "    for sess in data_pre:\n",
    "        if sess[5] == 'B':\n",
    "            day = 0\n",
    "        else:\n",
    "            day = int(re.findall(r'\\d+',sess[5:])[0])\n",
    "        days[ind] = day\n",
    "        ind= ind+1\n",
    "    a = np.argsort(days)\n",
    "    dKeys = list(data_pre.keys())\n",
    "    # calculte high speed period, do 3 sessions per plot, and stor in ppt\n",
    "    ind = 0;\n",
    "    hi = sgrp.attrs['hi']\n",
    "    th_weak = sgrp.attrs['th_weak']\n",
    "    for aa in range(0,len(data_pre)):\n",
    "        sess = dKeys[a[aa]]\n",
    "        speed = data_pre[sess]['speed']['speed']\n",
    "        speed = speed.T\n",
    "        sOnset = FindMvmtOnset2(speed, th_weak,th_strong ,hi,hiWin,thWin,shift)\n",
    "        subgrp = grp.create_group(sess)\n",
    "        ssubgrp = subgrp.create_group('Pre')\n",
    "        ssubgrp['mvmtOnset'] = sOnset\n",
    "        if sess in data_post.keys():\n",
    "            speed = data_post[sess]['speed']['speed']\n",
    "            speed = speed.T\n",
    "            sOnset = FindMvmtOnset2(speed, th_weak,th_strong ,hi,hiWin,thWin,shift)\n",
    "            spsubgrp = subgrp.create_group('Post')\n",
    "            spsubgrp['mvmtOnset'] = sOnset\n",
    "        \n",
    "f.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOnsetOrPeriod(m,s,period,OPtype,fileName='OnsetsAndPeriods.hdf5'):\n",
    "    # takes in a file name and return all the mice that exsits in file\n",
    "    with h5py.File(fileName,'r') as hf:\n",
    "        if  m+'/'+s+'/'+period+'/'+ OPtype not in hf:\n",
    "            print(m+'/'+s+'/'+period+'/'+ OPtype +' NOT in FILE')\n",
    "            return []        \n",
    "        else: \n",
    "            return hf[m][s][period][OPtype].value\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> double check that speed ONSET was saved properly, IO function works, and th make sense for post infusion data </b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "I deleted session: 0761_day1\n",
      "I deleted session: 0761_day10\n",
      "I deleted session: 0761_day12\n",
      "I deleted session: 0761_day2\n",
      "I deleted session: 0761_day4\n",
      "I deleted session: 0761_day6\n",
      "I deleted session: 0761_day8\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "I deleted session: 1208_day10\n",
      "I deleted session: 1208_day12\n",
      "I deleted session: 1208_day14\n",
      "I deleted session: 1208_day2\n",
      "I deleted session: 1208_day4\n",
      "I deleted session: 1208_day6\n",
      "I deleted session: 1208_day8\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "cleaning up speed data\n",
      "cleaning up speed data\n",
      "I deleted session: 1222_day11\n",
      "I deleted session: 1222_day13\n",
      "I deleted session: 1222_day2\n",
      "I deleted session: 1222_day3\n",
      "I deleted session: 1222_day5\n",
      "I deleted session: 1222_day7\n",
      "I deleted session: 1222_day9\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n"
     ]
    }
   ],
   "source": [
    "# define presentation params:\n",
    "prs = Presentation()\n",
    "prs.slide_width = Inches(11)\n",
    "title_layout = prs.slide_layouts[5] \n",
    "title_slide_layout = prs.slide_layouts[0]\n",
    "\n",
    "slide = prs.slides.add_slide(title_slide_layout)\n",
    "slide.shapes.title.text = 'Mvmt onset'\n",
    "# define figure params:\n",
    "lf = {'left':0.30, 'top':1.30, 'height':5.80, 'width':20.10}\n",
    "fArgs = {'left':Inches(lf['left']),'top':Inches(lf['top']), 'height':Inches(lf['height']), 'width':Inches(lf['width'])}\n",
    "Colors = CP('mvmtType') \n",
    "\n",
    "# get mice list:\n",
    "miceList = getMiceList(Files[0])\n",
    "# prepare data storage for segments:\n",
    "# make plot and save as ppt\n",
    "for m in miceList:\n",
    "    data = getData(Files[0],['speed'],period ='Pre', mice=m)\n",
    "    data_post = getData(Files[0],['speed'],period ='Post', mice=m)\n",
    "    days = np.zeros(len(data))\n",
    "    ind = 0\n",
    "    # sort by session for my own OCD\n",
    "    for sess in data:\n",
    "        if sess[5] == 'B':\n",
    "            day = 0\n",
    "        else:\n",
    "            day = int(re.findall(r'\\d+',sess[5:])[0])\n",
    "        days[ind] = day\n",
    "        ind= ind+1\n",
    "    a = np.argsort(days)\n",
    "    dKeys = list(data.keys())\n",
    "    # calculte high speed period, do 3 sessions per plot, and stor in ppt\n",
    "    ind = 0;\n",
    "    for aa in range(0,len(data)):\n",
    "        sess = dKeys[a[aa]]\n",
    "        speed = data[sess]['speed']['speed']\n",
    "        speed = speed.T\n",
    "        smoothSpeed = smooth(speed,20)\n",
    "        dt  = 1/data[sess]['speed']['Fs']\n",
    "        if ind%3==0:\n",
    "            fig, ax = plt.subplots(3,1,figsize=(lf['width'],lf['height']),\n",
    "                                   gridspec_kw = {'top':0.995,'bottom':0.008,'wspace':0.1})\n",
    "            fig.set_size_inches(lf['width'],lf['height'],forward=True)\n",
    "            fig.subplots_adjust(left=0.03, right=0.99)\n",
    "            slide = prs.slides.add_slide(title_layout)\n",
    "            slide.shapes.title.text = m #+ 'params: th_weak='+ str(round(th_weak,2)) + ' hi='+ str(round(hi,2))\n",
    "        try:    \n",
    "            sOnset = getOnsetOrPeriod(m,sess,'Pre','mvmtOnset')\n",
    "            t = np.linspace(0,len(speed)*dt,len(speed))\n",
    "            ax[ind%3].plot(t,speed)\n",
    "            ax[ind%3].plot(t,smoothSpeed, color='black')\n",
    "            ax[ind%3].plot(t[sOnset],smoothSpeed[sOnset],'X',color='firebrick')\n",
    "            ax[ind%3].set_xlim(0,600)\n",
    "            ax[ind%3].set_title(sess)\n",
    "            \n",
    "            if sess in data_post.keys():\n",
    "                pic = plt2pptx(slide, fig, **fArgs)\n",
    "                plt.close(fig)\n",
    "                fig, ax = plt.subplots(3,1,figsize=(lf['width'],lf['height']),\n",
    "                                   gridspec_kw = {'top':0.995,'bottom':0.008,'wspace':0.1})\n",
    "                fig.set_size_inches(lf['width'],lf['height'],forward=True)\n",
    "                fig.subplots_adjust(left=0.03, right=0.99)\n",
    "                slide = prs.slides.add_slide(title_layout)\n",
    "                slide.shapes.title.text = m +sess +'_post'#+ 'params: th_weak='+ str(round(th_weak,2)) + ' hi='+ st\n",
    "                \n",
    "                sOnset = getOnsetOrPeriod(m,sess,'Post','mvmtOnset')\n",
    "                speed = data_post[sess]['speed']['speed']\n",
    "                speed = speed.T\n",
    "                smoothSpeed = smooth(speed,20)\n",
    "                t = np.linspace(0,len(speed)*dt,len(speed))\n",
    "                for ind in range(3):\n",
    "                    if ind ==2:\n",
    "                        ax[ind%3].plot(t[ind*600:],speed[ind*600:])\n",
    "                    else:\n",
    "                        ax[ind%3].plot(t[ind*600:(ind+1)*600],speed[ind*600:(ind+1)*600])\n",
    "                    ax[ind%3].plot(t,smoothSpeed, color='black')\n",
    "                    ax[ind%3].plot(t[sOnset],smoothSpeed[sOnset],'X',color='firebrick')\n",
    "                pic = plt2pptx(slide, fig, **fArgs)\n",
    "                plt.close(fig)\n",
    "        except:\n",
    "            print('error')\n",
    "        if ind%3==2 or aa ==len(data)-1:\n",
    "            pic = plt2pptx(slide, fig, **fArgs)\n",
    "            plt.close(fig)\n",
    "        ind = ind+1\n",
    "prs.save('ppts/SpeedOnset_check.pptx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
